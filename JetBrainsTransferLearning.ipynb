{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning T5 model with PyTorch\n",
    "\n",
    "# Importing libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import os\n",
    "\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# rich: for a better display on terminal\n",
    "from rich.table import Column, Table\n",
    "from rich import box\n",
    "from rich.console import Console\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# define a rich console logger\n",
    "console = Console(record=True)\n",
    "\n",
    "# to display dataframe in ASCII format\n",
    "def display_df(df):\n",
    "    \"\"\"display dataframe in ASCII format\"\"\"\n",
    "\n",
    "    console = Console()\n",
    "    table = Table(\n",
    "        Column(\"source_text\", justify=\"center\"),\n",
    "        Column(\"target_text\", justify=\"center\"),\n",
    "        title=\"Sample Data\",\n",
    "        pad_edge=False,\n",
    "        box=box.ASCII,\n",
    "    )\n",
    "\n",
    "    for i, row in enumerate(df.values.tolist()):\n",
    "        table.add_row(row[0], row[1])\n",
    "\n",
    "    console.print(table)\n",
    "\n",
    "# training logger to log training progress\n",
    "training_logger = Table(\n",
    "    Column(\"Epoch\", justify=\"center\"),\n",
    "    Column(\"Steps\", justify=\"center\"),\n",
    "    Column(\"Loss\", justify=\"center\"),\n",
    "    title=\"Training Status\",\n",
    "    pad_edge=False,\n",
    "    box=box.ASCII,\n",
    ")\n",
    "\n",
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "### Dataset Class\n",
    "\n",
    "class YourDataSetClass(Dataset):\n",
    "    \"\"\"\n",
    "    Creating a custom dataset for reading the dataset and\n",
    "    loading it into the dataloader to pass it to the\n",
    "    neural network for finetuning the model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, dataframe, tokenizer, source_len, target_len, source_text, target_text\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a Dataset class\n",
    "\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): Input dataframe\n",
    "            tokenizer (transformers.tokenizer): Transformers tokenizer\n",
    "            source_len (int): Max length of source text\n",
    "            target_len (int): Max length of target text\n",
    "            source_text (str): column name of source text\n",
    "            target_text (str): column name of target text\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = target_len\n",
    "        self.target_text = self.data[target_text]\n",
    "        self.source_text = self.data[source_text]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"returns the length of dataframe\"\"\"\n",
    "\n",
    "        return len(self.target_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"return the input ids, attention masks and target ids\"\"\"\n",
    "\n",
    "        source_text = str(self.source_text[index])\n",
    "        target_text = str(self.target_text[index])\n",
    "\n",
    "        # cleaning data so as to ensure data is in string type\n",
    "        source_text = \" \".join(source_text.split())\n",
    "        target_text = \" \".join(target_text.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus(\n",
    "            [source_text],\n",
    "            max_length=self.source_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        target = self.tokenizer.batch_encode_plus(\n",
    "            [target_text],\n",
    "            max_length=self.summ_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        source_ids = source[\"input_ids\"].squeeze()\n",
    "        source_mask = source[\"attention_mask\"].squeeze()\n",
    "        target_ids = target[\"input_ids\"].squeeze()\n",
    "        target_mask = target[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\n",
    "            \"source_ids\": source_ids.to(dtype=torch.long),\n",
    "            \"source_mask\": source_mask.to(dtype=torch.long),\n",
    "            \"target_ids\": target_ids.to(dtype=torch.long),\n",
    "            \"target_ids_y\": target_ids.to(dtype=torch.long),\n",
    "        }\n",
    "\n",
    "### Train\n",
    "\n",
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to be called for training with the parameters passed from main function\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    for _, data in enumerate(loader, 0):\n",
    "        y = data[\"target_ids\"].to(device, dtype=torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data[\"source_ids\"].to(device, dtype=torch.long)\n",
    "        mask = data[\"source_mask\"].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=ids,\n",
    "            attention_mask=mask,\n",
    "            decoder_input_ids=y_ids,\n",
    "            labels=lm_labels,\n",
    "        )\n",
    "        loss = outputs[0]\n",
    "\n",
    "        if _ % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            training_logger.add_row(str(epoch), str(_), str(loss))\n",
    "            console.print(training_logger)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "### Validate\n",
    "\n",
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to evaluate model for predictions\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "              input_ids = ids,\n",
    "              attention_mask = mask, \n",
    "              max_length=150, \n",
    "              num_beams=2,\n",
    "              repetition_penalty=2.5, \n",
    "              length_penalty=1.0, \n",
    "              early_stopping=True\n",
    "              )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "            if _%100==0:\n",
    "              console.print(f'Completed {_}')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "    return predictions, actuals\n",
    "\n",
    "\n",
    "### T5 Trainer\n",
    "\n",
    "def T5Trainer(\n",
    "    dataframe, source_text, target_text, model_params, output_dir=\"./outputs/\"\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    T5 trainer\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Set random seeds and deterministic pytorch for reproducibility\n",
    "    torch.manual_seed(model_params[\"SEED\"])  # pytorch random seed\n",
    "    np.random.seed(model_params[\"SEED\"])  # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # logging\n",
    "    console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
    "\n",
    "    # tokenzier for encoding the text\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "\n",
    "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary.\n",
    "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
    "    model = model.to(device)\n",
    "\n",
    "    # logging\n",
    "    console.log(f\"[Data]: Reading data...\\n\")\n",
    "\n",
    "    # Importing the raw dataset\n",
    "    dataframe = dataframe[[source_text, target_text]]\n",
    "    display_df(dataframe.head(2))\n",
    "\n",
    "    # Creation of Dataset and Dataloader\n",
    "    # Defining the train size. So 80% of the data will be used for training and the rest for validation.\n",
    "    train_size = 0.8\n",
    "    train_dataset = dataframe.sample(frac=train_size, random_state=model_params[\"SEED\"])\n",
    "    val_dataset = dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    console.print(f\"FULL Dataset: {dataframe.shape}\")\n",
    "    console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
    "    console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\n",
    "\n",
    "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
    "    training_set = YourDataSetClass(\n",
    "        train_dataset,\n",
    "        tokenizer,\n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
    "        source_text,\n",
    "        target_text,\n",
    "    )\n",
    "    val_set = YourDataSetClass(\n",
    "        val_dataset,\n",
    "        tokenizer,\n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
    "        source_text,\n",
    "        target_text,\n",
    "    )\n",
    "\n",
    "    # Defining the parameters for creation of dataloaders\n",
    "    train_params = {\n",
    "        \"batch_size\": model_params[\"TRAIN_BATCH_SIZE\"],\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    val_params = {\n",
    "        \"batch_size\": model_params[\"VALID_BATCH_SIZE\"],\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    print(training_loader)\n",
    "    \n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "    # Defining the optimizer that will be used to tune the weights of the network in the training session.\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(), lr=model_params[\"LEARNING_RATE\"]\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    console.log(f\"[Initiating Fine Tuning]...\\n\")\n",
    "\n",
    "    for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
    "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "\n",
    "    console.log(f\"[Saving Model]...\\n\")\n",
    "    # Saving the model after training\n",
    "    path = os.path.join(output_dir, \"model_files\")\n",
    "    model.save_pretrained(path)\n",
    "    tokenizer.save_pretrained(path)\n",
    "\n",
    "    # evaluating test dataset\n",
    "    console.log(f\"[Initiating Validation]...\\n\")\n",
    "    for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
    "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "        final_df = pd.DataFrame({\"Generated Text\": predictions, \"Actual Text\": actuals})\n",
    "        final_df.to_csv(os.path.join(output_dir, \"predictions.csv\"))\n",
    "\n",
    "    console.save_text(os.path.join(output_dir, \"logs.txt\"))\n",
    "\n",
    "    console.log(f\"[Validation Completed.]\\n\")\n",
    "    console.print(\n",
    "        f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\"\n",
    "    )\n",
    "    console.print(\n",
    "        f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\"\n",
    "    )\n",
    "    console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")\n",
    "\n",
    "### Model Parameters\n",
    "\n",
    "# let's define model parameters specific to T5\n",
    "model_params = {\n",
    "    \"MODEL\": \"t5-small\",  # model_type: t5-base/t5-large\n",
    "    \"TRAIN_BATCH_SIZE\": 16,  # training batch size\n",
    "    \"VALID_BATCH_SIZE\": 8,  # validation batch size\n",
    "    \"TRAIN_EPOCHS\": 5,  # number of training epochs\n",
    "    \"VAL_EPOCHS\": 1,  # number of validation epochs\n",
    "    \"LEARNING_RATE\": 1e-1,  # learning rate\n",
    "    \"MAX_SOURCE_TEXT_LENGTH\": 512,  # max length of source text\n",
    "    \"MAX_TARGET_TEXT_LENGTH\": 16,  # max length of target text\n",
    "    \"SEED\": 12,  # set seed for reproducibility\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/resta/python-virtual-environments/T5TL/lib/python3.8/site-packages/pandas/core/indexing.py:1951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[selected_item_labels] = value\n",
      "/tmp/ipykernel_3767/3259638793.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['target'] = data['target'].map(languages)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detect language: Accordingly, federal agencies...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Detect language: For the fire alarm, see PANYN...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Detect language: ستحتاج هذه الحلول إلى معالجة ...</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detect language: ناومی ولف کا غلط جواب نہیں</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detect language: Enfin, il a demandé au secrét...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Detect language: أنت تعرف أنه ربما حوالي عشرين...</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Detect language: นักสืบ FBI บางคนคลาบแคลงเรื่อ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Detect language: یہ دلچسپ ہے کہ معیشت میں ایک ...</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Detect language: Sınırsız mandala yığınının ma...</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Detect language: تسلق العديد من ضباط PAPD أيضا...</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   target\n",
       "0  Detect language: Accordingly, federal agencies...  English\n",
       "1  Detect language: For the fire alarm, see PANYN...  English\n",
       "2  Detect language: ستحتاج هذه الحلول إلى معالجة ...   Arabic\n",
       "3        Detect language: ناومی ولف کا غلط جواب نہیں     Urdu\n",
       "4  Detect language: Enfin, il a demandé au secrét...   French\n",
       "5  Detect language: أنت تعرف أنه ربما حوالي عشرين...   Arabic\n",
       "6  Detect language: นักสืบ FBI บางคนคลาบแคลงเรื่อ...     Thai\n",
       "7  Detect language: یہ دلچسپ ہے کہ معیشت میں ایک ...     Urdu\n",
       "8  Detect language: Sınırsız mandala yığınının ma...  Turkish\n",
       "9  Detect language: تسلق العديد من ضباط PAPD أيضا...   Arabic"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"xnli_test.tsv\"\n",
    "\n",
    "df = pd.read_csv(path, sep='\\t')\n",
    "data = df[['sentence1','language']]\n",
    "data.columns = ['text','target']\n",
    "data.loc[:,\"text\"] = \"Detect language: \" + data[\"text\"]\n",
    "languages = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"bg\": \"Bulgarian\",\n",
    "    \"de\": 'German',\n",
    "    \"el\": \"Greek\",\n",
    "    \"en\": \"English\",\n",
    "    \"es\": 'Spanish',\n",
    "    \"fr\": 'French',\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sw\": \"Swahili\",\n",
    "    \"th\": \"Thai\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"ur\": \"Urdu\",\n",
    "    \"vi\": \"Vietnamese\",\n",
    "    \"zh\": \"Chinese\",\n",
    "}\n",
    "data['target'] = data['target'].map(languages)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                 Training Status                                 </span>\n",
       "+-------------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                              Loss                              </span>|\n",
       "|------+-------+----------------------------------------------------------------|\n",
       "|  0   |   0   |   tensor(4.9041, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   |  100  |   tensor(0.0419, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   |  200  |   tensor(0.0003, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   |  300  |   tensor(0.0038, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   |  400  | tensor(7.0123e-09, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  |   tensor(0.0004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   |  600  | tensor(1.9457e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  700  | tensor(7.5860e-08, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  800  | tensor(2.5008e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  900  |   tensor(0.0039, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 1000  |   tensor(0.0002, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 1100  |   tensor(0.0890, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 1200  |   tensor(0.0303, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 1300  |   tensor(0.0170, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 1400  | tensor(1.5034e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  |   tensor(0.0070, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 1600  | tensor(1.9582e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1700  |   tensor(0.0278, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 1800  |   tensor(0.0002, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 1900  | tensor(3.3384e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(5.5436e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2100  |   tensor(1.1723, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 2200  |   tensor(0.1108, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 2300  | tensor(5.4186e-08, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2400  | tensor(8.3446e-07, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  |   tensor(0.0003, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 2600  | tensor(2.6499e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2700  |   tensor(0.0001, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 2800  | tensor(6.9016e-07, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2900  |   tensor(0.1239, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 3000  |   tensor(0.0002, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 3100  |   tensor(0.2230, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 3200  |   tensor(0.0002, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 3300  | tensor(8.0252e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3400  |   tensor(0.0001, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 3500  | tensor(1.2312e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3600  |   tensor(0.0054, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  0   | 3700  | tensor(3.1829e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.7311e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  100  | tensor(9.7031e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  200  | tensor(1.2571e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  300  | tensor(7.4849e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  400  | tensor(2.3009e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(3.2467e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  600  | tensor(2.2335e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  700  |   tensor(0.0006, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  1   |  800  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  1   |  900  |   tensor(0.0402, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  1   | 1000  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  1   | 1100  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  1   | 1200  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  1   | 1300  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  1   | 1400  | tensor(1.4025e-08, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  |   tensor(0.0067, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  1   | 1600  |   tensor(0.0721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  1   | 1700  | tensor(4.5850e-09, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1800  | tensor(1.2753e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1900  | tensor(5.9082e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.7309e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2100  |   tensor(0.0270, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  1   | 2200  | tensor(1.7030e-08, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2300  | tensor(4.4702e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2400  | tensor(3.8601e-07, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  |   tensor(0.0002, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  1   | 2600  | tensor(9.3294e-08, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2700  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  1   | 2800  |   tensor(0.0006, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  1   | 2900  | tensor(4.7684e-09, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  |   tensor(0.5001, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  1   | 3100  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  1   | 3200  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  1   | 3300  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  1   | 3400  | tensor(1.3028e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3500  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  1   | 3600  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  1   | 3700  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   |   0   |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   |  100  |   tensor(0.8380, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  2   |  200  | tensor(4.4152e-09, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  300  | tensor(1.5497e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  400  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   |  500  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   |  600  |   tensor(0.0142, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  2   |  700  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   |  800  |   tensor(0.0006, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  2   |  900  | tensor(6.3326e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 1100  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 1200  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 1300  |   tensor(1.4789, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  2   | 1400  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 1500  | tensor(4.6359e-07, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1600  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 1700  |   tensor(0.0007, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  2   | 1800  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 1900  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 2000  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 2100  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 2200  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 2300  | tensor(5.2450e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 2400  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 2500  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 2600  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 2700  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 2800  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 2900  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 3000  | tensor(2.0705e-07, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 3100  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 3200  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 3300  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 3400  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 3500  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  2   | 3600  | tensor(1.0837e-08, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 3700  | tensor(6.5565e-08, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(1.5549e-08, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  100  | tensor(5.4186e-09, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  200  | tensor(1.0196e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  300  |   tensor(0.0249, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   |  400  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  3   |  500  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  3   |  600  |   tensor(0.1051, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   |  700  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  3   |  800  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  3   |  900  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  3   | 1000  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  3   | 1100  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  3   | 1200  | tensor(6.6227e-09, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1300  | tensor(4.6803e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1400  |   tensor(0.6348, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 1500  |   tensor(0.0410, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 1600  |   tensor(0.0343, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 1700  |   tensor(0.0013, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 1800  |   tensor(0.0005, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 1900  |   tensor(0.0012, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 2000  |   tensor(0.1224, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 2100  |   tensor(0.0264, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 2200  |   tensor(0.0007, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 2300  |   tensor(0.0006, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 2400  | tensor(4.0537e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 2500  |   tensor(0.0010, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 2600  |   tensor(0.0182, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 2700  | tensor(9.5862e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 2800  | tensor(7.9517e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 2900  | tensor(2.0663e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 3000  |   tensor(0.0002, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 3100  | tensor(1.0028e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 3200  | tensor(6.0796e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 3300  | tensor(5.0707e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 3400  |   tensor(0.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 3500  |   tensor(0.0170, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  3   | 3600  | tensor(6.2948e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 3700  | tensor(1.4363e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   |   tensor(0.3066, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   |  100  |   tensor(0.0842, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   |  200  |   tensor(0.0009, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   |  300  | tensor(7.8829e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |  400  | tensor(1.4684e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |  500  | tensor(5.9148e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |  600  |   tensor(0.0025, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   |  700  | tensor(6.7492e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |  800  |   tensor(0.0002, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   |  900  |   tensor(0.0298, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 1000  | tensor(1.9073e-07, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1100  |   tensor(0.0033, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 1200  | tensor(1.5646e-07, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1300  | tensor(5.8776e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1400  |   tensor(0.0005, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 1500  | tensor(1.5951e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1600  |   tensor(0.2159, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 1700  |   tensor(0.0005, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 1800  |   tensor(0.0440, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 1900  | tensor(1.7285e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 2000  | tensor(7.1005e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 2100  | tensor(7.4344e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 2200  |   tensor(0.0006, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 2300  | tensor(1.3737e-06, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 2400  | tensor(9.4336e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 2500  |   tensor(0.0107, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 2600  |   tensor(0.0023, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 2700  |   tensor(0.3725, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 2800  |   tensor(0.1759, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 2900  | tensor(5.1182e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 3000  |   tensor(0.0019, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 3100  | tensor(4.6274e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 3200  | tensor(1.2398e-07, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 3300  |   tensor(0.0001, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 3400  |     tensor(0., device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)    |\n",
       "|  4   | 3500  |   tensor(0.0014, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 3600  |   tensor(0.0128, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)  |\n",
       "|  4   | 3700  | tensor(3.9652e-05, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+-------------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                 Training Status                                 \u001b[0m\n",
       "+-------------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                             Loss                              \u001b[0m|\n",
       "|------+-------+----------------------------------------------------------------|\n",
       "|  0   |   0   |   tensor(4.9041, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   |  100  |   tensor(0.0419, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   |  200  |   tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   |  300  |   tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   |  400  | tensor(7.0123e-09, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  |   tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   |  600  | tensor(1.9457e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  700  | tensor(7.5860e-08, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  800  | tensor(2.5008e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  900  |   tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 1000  |   tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 1100  |   tensor(0.0890, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 1200  |   tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 1300  |   tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 1400  | tensor(1.5034e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  |   tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 1600  | tensor(1.9582e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1700  |   tensor(0.0278, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 1800  |   tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 1900  | tensor(3.3384e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(5.5436e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2100  |   tensor(1.1723, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 2200  |   tensor(0.1108, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 2300  | tensor(5.4186e-08, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2400  | tensor(8.3446e-07, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  |   tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 2600  | tensor(2.6499e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2700  |   tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 2800  | tensor(6.9016e-07, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2900  |   tensor(0.1239, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 3000  |   tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 3100  |   tensor(0.2230, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 3200  |   tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 3300  | tensor(8.0252e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3400  |   tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 3500  | tensor(1.2312e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3600  |   tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  0   | 3700  | tensor(3.1829e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.7311e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  100  | tensor(9.7031e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  200  | tensor(1.2571e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  300  | tensor(7.4849e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  400  | tensor(2.3009e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(3.2467e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  600  | tensor(2.2335e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  700  |   tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  1   |  800  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  1   |  900  |   tensor(0.0402, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  1   | 1000  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  1   | 1100  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  1   | 1200  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  1   | 1300  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  1   | 1400  | tensor(1.4025e-08, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  |   tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  1   | 1600  |   tensor(0.0721, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  1   | 1700  | tensor(4.5850e-09, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1800  | tensor(1.2753e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1900  | tensor(5.9082e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.7309e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2100  |   tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  1   | 2200  | tensor(1.7030e-08, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2300  | tensor(4.4702e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2400  | tensor(3.8601e-07, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  |   tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  1   | 2600  | tensor(9.3294e-08, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2700  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  1   | 2800  |   tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  1   | 2900  | tensor(4.7684e-09, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  |   tensor(0.5001, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  1   | 3100  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  1   | 3200  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  1   | 3300  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  1   | 3400  | tensor(1.3028e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3500  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  1   | 3600  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  1   | 3700  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   |   0   |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   |  100  |   tensor(0.8380, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  2   |  200  | tensor(4.4152e-09, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  300  | tensor(1.5497e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  400  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   |  500  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   |  600  |   tensor(0.0142, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  2   |  700  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   |  800  |   tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  2   |  900  | tensor(6.3326e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 1100  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 1200  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 1300  |   tensor(1.4789, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  2   | 1400  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 1500  | tensor(4.6359e-07, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1600  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 1700  |   tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  2   | 1800  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 1900  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 2000  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 2100  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 2200  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 2300  | tensor(5.2450e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 2400  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 2500  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 2600  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 2700  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 2800  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 2900  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 3000  | tensor(2.0705e-07, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 3100  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 3200  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 3300  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 3400  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 3500  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  2   | 3600  | tensor(1.0837e-08, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 3700  | tensor(6.5565e-08, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(1.5549e-08, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  100  | tensor(5.4186e-09, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  200  | tensor(1.0196e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  300  |   tensor(0.0249, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   |  400  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  3   |  500  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  3   |  600  |   tensor(0.1051, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   |  700  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  3   |  800  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  3   |  900  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  3   | 1000  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  3   | 1100  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  3   | 1200  | tensor(6.6227e-09, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1300  | tensor(4.6803e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1400  |   tensor(0.6348, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 1500  |   tensor(0.0410, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 1600  |   tensor(0.0343, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 1700  |   tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 1800  |   tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 1900  |   tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 2000  |   tensor(0.1224, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 2100  |   tensor(0.0264, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 2200  |   tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 2300  |   tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 2400  | tensor(4.0537e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 2500  |   tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 2600  |   tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 2700  | tensor(9.5862e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 2800  | tensor(7.9517e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 2900  | tensor(2.0663e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 3000  |   tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 3100  | tensor(1.0028e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 3200  | tensor(6.0796e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 3300  | tensor(5.0707e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 3400  |   tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 3500  |   tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  3   | 3600  | tensor(6.2948e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 3700  | tensor(1.4363e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   |   tensor(0.3066, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   |  100  |   tensor(0.0842, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   |  200  |   tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   |  300  | tensor(7.8829e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |  400  | tensor(1.4684e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |  500  | tensor(5.9148e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |  600  |   tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   |  700  | tensor(6.7492e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |  800  |   tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   |  900  |   tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 1000  | tensor(1.9073e-07, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1100  |   tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 1200  | tensor(1.5646e-07, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1300  | tensor(5.8776e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1400  |   tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 1500  | tensor(1.5951e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1600  |   tensor(0.2159, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 1700  |   tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 1800  |   tensor(0.0440, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 1900  | tensor(1.7285e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 2000  | tensor(7.1005e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 2100  | tensor(7.4344e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 2200  |   tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 2300  | tensor(1.3737e-06, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 2400  | tensor(9.4336e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 2500  |   tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 2600  |   tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 2700  |   tensor(0.3725, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 2800  |   tensor(0.1759, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 2900  | tensor(5.1182e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 3000  |   tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 3100  | tensor(4.6274e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 3200  | tensor(1.2398e-07, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 3300  |   tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 3400  |     tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)    |\n",
       "|  4   | 3500  |   tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 3600  |   tensor(0.0128, device='cuda:0', grad_fn=<NllLossBackward0>)  |\n",
       "|  4   | 3700  | tensor(3.9652e-05, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+-------------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:03:13] </span><span style=\"font-weight: bold\">[</span>Saving Model<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                <a href=\"file:///tmp/ipykernel_3767/1987615841.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1987615841.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3767/1987615841.py#296\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">296</span></a>\n",
       "                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:03:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mSaving Model\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                \u001b]8;id=32100;file:///tmp/ipykernel_3767/1987615841.py\u001b\\\u001b[2m1987615841.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=359505;file:///tmp/ipykernel_3767/1987615841.py#296\u001b\\\u001b[2m296\u001b[0m\u001b]8;;\u001b\\\n",
       "                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:03:16] </span><span style=\"font-weight: bold\">[</span>Initiating Validation<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                       <a href=\"file:///tmp/ipykernel_3767/1987615841.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1987615841.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3767/1987615841.py#303\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">303</span></a>\n",
       "                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:03:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Validation\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                       \u001b]8;id=66339;file:///tmp/ipykernel_3767/1987615841.py\u001b\\\u001b[2m1987615841.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=627449;file:///tmp/ipykernel_3767/1987615841.py#303\u001b\\\u001b[2m303\u001b[0m\u001b]8;;\u001b\\\n",
       "                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m100\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m200\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m300\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m400\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m500\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m600\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">700</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m700\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m800\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">900</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m900\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m1000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1100</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m1100\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1200</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m1200\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1300</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m1300\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1400</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m1400\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1500</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m1500\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1600</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m1600\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1700</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m1700\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1800</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m1800\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:07:33] </span><span style=\"font-weight: bold\">[</span>Validation Completed.<span style=\"font-weight: bold\">]</span>                                          <a href=\"file:///tmp/ipykernel_3767/1987615841.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1987615841.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_3767/1987615841.py#311\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">311</span></a>\n",
       "                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:07:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mValidation Completed.\u001b[1m]\u001b[0m                                          \u001b]8;id=417460;file:///tmp/ipykernel_3767/1987615841.py\u001b\\\u001b[2m1987615841.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=88310;file:///tmp/ipykernel_3767/1987615841.py#311\u001b\\\u001b[2m311\u001b[0m\u001b]8;;\u001b\\\n",
       "                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span> Model saved @ outputs/model_files\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m Model saved @ outputs/model_files\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Validation<span style=\"font-weight: bold\">]</span> Generation on Validation data saved @ outputs/predictions.csv\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mValidation\u001b[1m]\u001b[0m Generation on Validation data saved @ outputs/predictions.csv\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Logs<span style=\"font-weight: bold\">]</span> Logs saved @ outputs/logs.txt\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mLogs\u001b[1m]\u001b[0m Logs saved @ outputs/logs.txt\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T5Trainer(\n",
    "    dataframe=data,\n",
    "    source_text=\"text\",\n",
    "    target_text=\"target\",\n",
    "    model_params=model_params,\n",
    "    output_dir=\"outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('outputs/predictions.csv')\n",
    "result['Generated Text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
